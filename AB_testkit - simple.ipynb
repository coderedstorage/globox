{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AB Testing Kit\n",
    "* [Guideline for AB testing](https://www.kaggle.com/code/ekrembayar/a-b-testing-step-by-step-hypothesis-testing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_effectsize, proportions_ztest\n",
    "from statsmodels.stats.power import NormalIndPower, TTestIndPower, zt_ind_solve_power\n",
    "from scipy.stats import norm, ttest_ind\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics as st\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prepping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ab = pd.read_csv(r\"C:\\Users\\Master\\Documents\\data_analytics\\globox\\ab_test_final.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_df(dataframe, head):\n",
    "    print(\"\\n\" + \" DATAFRAME SUMMARY \".center(70, '=') + \"\")\n",
    "    print(\"\\n\" + \" INFO \".center(70, '-'))\n",
    "    info_df = dataframe.dtypes.to_frame(name='Dtype')\n",
    "    info_df['Non-Null'] = dataframe.notnull().sum()\n",
    "    info_df['Unique'] = dataframe.nunique()\n",
    "    info_df['Duplicate'] = dataframe.T.duplicated().sum()\n",
    "    info_df['Missing'] = dataframe.isnull().sum()\n",
    "    print(info_df)\n",
    "    print('\\nRows: {}'.format(dataframe.shape[0]))\n",
    "    print('Columns: {}'.format(dataframe.shape[1]))\n",
    "    print(\"\\n\" + \" DESCRIBE \".center(70, '-'))\n",
    "    print(dataframe.describe().T)\n",
    "    print(\"\\n\" + \" PERCENTILES \".center(70, '-'))\n",
    "    print(dataframe.describe([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n",
    "    print(\"\\n\" + \" HEAD \".center(70, '-'))\n",
    "    print(dataframe.head(head))\n",
    "display(check_df(df_ab,1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table module\n",
    "# Define column order\n",
    "column_order = ['users', 'conversions', 'conversion_rate', 'total_spend_USD', 'avg_spend_USD']\n",
    "# Calculate summary statistics by test_group and country_name\n",
    "summary = df_ab.groupby(['test_group','country_name']).agg({'conversion': 'sum', 'spend_USD': 'sum', 'user_id': 'nunique'})\n",
    "summary.columns = ['conversions', 'total_spend_USD', 'users']\n",
    "summary['conversion_rate'] = summary['conversions'] / summary['users']\n",
    "summary['avg_spend_USD'] = summary['total_spend_USD'] / summary['users']\n",
    "summary = summary[column_order]\n",
    "# Calculate subtotals by test_group\n",
    "sub = df_ab.groupby('test_group').agg({'conversion': 'sum', 'spend_USD': 'sum', 'user_id': 'nunique'})\n",
    "sub.columns = ['conversions', 'total_spend_USD', 'users']\n",
    "sub['conversion_rate'] = sub['conversions'] / sub['users']\n",
    "sub['avg_spend_USD'] = sub['total_spend_USD'] / sub['users']\n",
    "sub = sub[column_order]\n",
    "sub.index = pd.MultiIndex.from_tuples([(x, 'Subtotal') for x in sub.index])\n",
    "# Calculate grand total\n",
    "total = pd.DataFrame({\n",
    "    'conversions': [df_ab['conversion'].sum()],\n",
    "    'total_spend_USD': [df_ab['spend_USD'].sum()],\n",
    "    'users': [df_ab['user_id'].nunique()]})\n",
    "total['conversion_rate'] = total['conversions'] / total['users']\n",
    "total['avg_spend_USD'] = total['total_spend_USD'] / total['users']\n",
    "total.index = pd.MultiIndex.from_tuples([('Grand Total', '')])\n",
    "total = total[column_order]\n",
    "# Merge summary statistics, subtotals, and grand total and display results\n",
    "result = pd.concat([summary, sub, total])\n",
    "# Export summary table module\n",
    "file_path = f\"C:\\\\Users\\\\Master\\\\Documents\\\\data_analytics\\\\globox\\\\summary_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.csv\"\n",
    "# Save result DataFrame to CSV file\n",
    "result.to_csv(file_path)\n",
    "display(result.head(200))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Country table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country View\n",
    "print(\"Country View:\")\n",
    "df_ab['lifespan_conversion'] = df_ab['user_lifespan_days'] * df_ab['conversion']\n",
    "test = df_ab.groupby(['country_name', 'test_group']).agg({'user_id': 'count', 'conversion': ['sum', 'mean'], 'spend_USD': ['sum', 'mean'], 'user_lifespan_days': 'mean', 'lifespan_conversion': 'sum'})\n",
    "test.columns = ['users', 'conversions', 'conversion_rate', 'total_spend', 'avg_spend', 'lifespan', 'lifespan_conversion']\n",
    "test['lifespan_conversion'] = test['lifespan_conversion'] / test['conversions']\n",
    "test['unconverted'] = test['users']-test['conversions']\n",
    "test['avg_spend_conversion'] = test['total_spend']/test['conversions'] \n",
    "test = test[['users', 'conversions', 'unconverted', 'conversion_rate', 'total_spend', 'avg_spend', 'avg_spend_conversion', 'lifespan', 'lifespan_conversion']]\n",
    "test = test.sort_values(by='users', ascending=False)\n",
    "display(test)\n",
    "df_ab = df_ab.drop('lifespan_conversion', axis = 1)\n",
    "\n",
    "print(\"\\nUSA Summary:\")\n",
    "# locate index  = 'USA'\n",
    "usa = test.loc['USA']\n",
    "display(usa)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average conversion rate and per user $ spend by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General conversions and spend \n",
    "df_ab['lifespan_conversion'] = df_ab['user_lifespan_days'] * df_ab['conversion']\n",
    "test = df_ab.groupby(['test_group']).agg({'user_id': 'count', 'conversion': ['sum', 'mean'], 'spend_USD': ['sum', 'mean'], 'user_lifespan_days': 'mean', 'lifespan_conversion': 'sum'})\n",
    "test.columns = ['users', 'conversions', 'conversion_rate', 'total_spend', 'avg_spend', 'lifespan', 'lifespan_conversion']\n",
    "test['lifespan_conversion'] = test['lifespan_conversion'] / test['conversions']\n",
    "test['unconverted'] = test['users']-test['conversions']\n",
    "test['avg_spend_conversion'] = test['total_spend']/test['conversions'] \n",
    "test = test[['users', 'conversions', 'unconverted', 'conversion_rate', 'total_spend', 'avg_spend', 'avg_spend_conversion', 'lifespan', 'lifespan_conversion']]\n",
    "display(test)\n",
    "df_ab = df_ab.drop('lifespan_conversion', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device conversions and spend \n",
    "df_ab['lifespan_conversion'] = df_ab['user_lifespan_days'] * df_ab['conversion']\n",
    "test = df_ab.groupby(['device', 'test_group']).agg({'user_id': 'count', 'conversion': ['sum', 'mean'], 'spend_USD': ['sum', 'mean'], 'user_lifespan_days': 'mean', 'lifespan_conversion': 'sum'})\n",
    "test.columns = ['users', 'conversions', 'conversion_rate', 'total_spend', 'avg_spend', 'lifespan', 'lifespan_conversion']\n",
    "test['lifespan_conversion'] = test['lifespan_conversion'] / test['conversions']\n",
    "test['unconverted'] = test['users']-test['conversions']\n",
    "test['avg_spend_conversion'] = test['total_spend']/test['conversions'] \n",
    "test = test[['users', 'conversions', 'unconverted', 'conversion_rate', 'total_spend', 'avg_spend', 'avg_spend_conversion', 'lifespan', 'lifespan_conversion']]\n",
    "display(test)\n",
    "df_ab = df_ab.drop('lifespan_conversion', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender conversions and spend \n",
    "df_ab['lifespan_conversion'] = df_ab['user_lifespan_days'] * df_ab['conversion']\n",
    "test = df_ab.groupby(['gender', 'test_group']).agg({'user_id': 'count', 'conversion': ['sum', 'mean'], 'spend_USD': ['sum', 'mean'], 'user_lifespan_days': 'mean', 'lifespan_conversion': 'sum'})\n",
    "test.columns = ['users', 'conversions', 'conversion_rate', 'total_spend', 'avg_spend', 'lifespan', 'lifespan_conversion']\n",
    "test['lifespan_conversion'] = test['lifespan_conversion'] / test['conversions']\n",
    "test['unconverted'] = test['users']-test['conversions']\n",
    "test['avg_spend_conversion'] = test['total_spend']/test['conversions'] \n",
    "test = test[['users', 'conversions', 'unconverted', 'conversion_rate', 'total_spend', 'avg_spend', 'avg_spend_conversion', 'lifespan', 'lifespan_conversion']]\n",
    "display(test)\n",
    "df_ab = df_ab.drop('lifespan_conversion', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort conversions and spend \n",
    "df_ab['lifespan_conversion'] = df_ab['user_lifespan_days'] * df_ab['conversion']\n",
    "test = df_ab.groupby(['cohort_month', 'test_group']).agg({'user_id': 'count', 'conversion': ['sum', 'mean'], 'spend_USD': ['sum', 'mean'], 'user_lifespan_days': 'mean', 'lifespan_conversion': 'sum'})\n",
    "test.columns = ['users', 'conversions', 'conversion_rate', 'total_spend', 'avg_spend', 'lifespan', 'lifespan_conversion']\n",
    "test['lifespan_conversion'] = test['lifespan_conversion'] / test['conversions']\n",
    "test['unconverted'] = test['users']-test['conversions']\n",
    "test['avg_spend_conversion'] = test['total_spend']/test['conversions'] \n",
    "test = test[['users', 'conversions', 'unconverted', 'conversion_rate', 'total_spend', 'avg_spend', 'avg_spend_conversion', 'lifespan', 'lifespan_conversion']]\n",
    "display(test)\n",
    "df_ab = df_ab.drop('lifespan_conversion', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert only\n",
    "convert = df_ab[df_ab['conversion']==1].groupby(['test_group', 'country_name', 'gender', 'device']).agg({'user_id': 'count', 'spend_USD': 'mean', 'user_lifespan_days': 'mean'})\n",
    "convert.columns = ['users', 'avg_spend', 'lifespan']\n",
    "# Export summary table module\n",
    "file_path = f\"C:\\\\Users\\\\Master\\\\Documents\\\\data_analytics\\\\globox\\\\convert_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.csv\"\n",
    "# Save result DataFrame to CSV file\n",
    "convert.to_csv(file_path)\n",
    "convert.head(200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programs\n",
    "* Application guidelines\n",
    "    * MDE or minimum detectable effect is expressed on relative change basis\n",
    "    * t_test: difference in means\n",
    "    * z_test: difference in proportions (large sample, > 30 observations)\n",
    "    * z_test_clt: difference in means, only if Central Limit Theorem applies (sample size > 30) i.e. t-test sans degrees of freedom - decommissioned but available in older version\n",
    "    * chi_sq_test: difference in proportions (small sample, < 30 observations) - not built\n",
    "* Sources\n",
    "    * [Link](https://www.cuemath.com/data/z-test/) pooled proportions se (z-test) \n",
    "    * [Link](https://cms.master.school/confidence-interval-and-hypothesis-testing-cheat-sheet) unpooled proportions se (z-test)\n",
    "    * [Link](https://online.stat.psu.edu/stat500/lesson/7/7.3/7.3.1/7.3.1.1) pooled se & df (t-test)\n",
    "    * [Link](https://online.stat.psu.edu/stat500/lesson/7/7.3/7.3.1/7.3.1.2) unpooled se (t-test)\n",
    "    * [Link](https://www.statology.org/satterthwaite-approximation/) unpooled df (t-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_test(control, treatment, alpha, pooled, full_report, scope_note, target_mde, power):\n",
    "    # convert series objects to NumPy arrays\n",
    "    control = np.asarray(control)\n",
    "    treatment = np.asarray(treatment)\n",
    "    # summary stats\n",
    "    control_mean = np.mean(control)\n",
    "    control_std = np.std(control)\n",
    "    control_size = len(control)\n",
    "    treatment_mean = np.mean(treatment)\n",
    "    treatment_std = np.std(treatment)\n",
    "    treatment_size = len(treatment)\n",
    "    combined_size = control_size + treatment_size\n",
    "    combined_value = control_size * control_mean + treatment_size * treatment_mean\n",
    "    p = combined_value / combined_size\n",
    "    combined_mean = p\n",
    "    combined_std = np.sqrt(((control_size - 1) * control_std**2 + (treatment_size - 1) * treatment_std**2 ) / (combined_size - 2))\n",
    "    # sample_stat and theoretical proportion p2 based on MDE\n",
    "    sample_stat = (treatment_mean - control_mean)\n",
    "    relative_change = sample_stat / control_mean\n",
    "    p2 = control_mean * (1 + relative_change)\n",
    "    pb = control_mean * (1 + target_mde)\n",
    "    # calculate se, cohen_d, ideal MDE-based combined sample size, actual MDE practical significance of cohen's d and test_stat\n",
    "    if pooled:  \n",
    "        se = np.sqrt(p * (1 - p) * (1 / control_size + 1 / treatment_size))\n",
    "        cohen_d = sample_stat / np.sqrt(p * (1 - p))\n",
    "        effect_size = proportion_effectsize(control_mean, p2)\n",
    "        min_combined_sample_size = NormalIndPower().solve_power(effect_size=effect_size, alpha=alpha, power=power, ratio=1)\n",
    "        theoretical_effect_size = proportion_effectsize(control_mean, pb)\n",
    "        try_combined_sample_size = NormalIndPower().solve_power(effect_size=theoretical_effect_size, alpha=alpha, power=power, ratio=1)\n",
    "    else:\n",
    "        se = np.sqrt(control_mean*(1-control_mean)/control_size + treatment_mean*(1-treatment_mean)/treatment_size)\n",
    "        cohen_d = sample_stat / np.sqrt((control_std**2 + treatment_std**2) / 2)\n",
    "        effect_size = proportion_effectsize(control_mean, p2)\n",
    "        n = NormalIndPower().solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
    "        min_combined_sample_size = 2 * n\n",
    "        theoretical_effect_size = proportion_effectsize(control_mean, pb)\n",
    "        k = NormalIndPower().solve_power(effect_size=theoretical_effect_size, alpha=alpha, power=power)\n",
    "        try_combined_sample_size = k * 2\n",
    "    practical_significance = \"large\" if cohen_d >= 0.8 else 'medium'if cohen_d >= 0.5 else 'small' if cohen_d >= 0.2 else \"little_effect\"\n",
    "    test_stat = sample_stat / se\n",
    "    # perform one-tailed test\n",
    "    p_value_1tail = stats.norm.sf(abs(test_stat))\n",
    "    critical_value_1tail = stats.norm.ppf(1 - alpha)\n",
    "    me_1tail = critical_value_1tail * se\n",
    "    decision_1tail = \"Reject_H0\" if p_value_1tail <= alpha else \"Fail_to_reject_H0\"\n",
    "    # perform two-tailed test\n",
    "    p_value_2tail = stats.norm.sf(abs(test_stat)) * 2\n",
    "    critical_value_2tail = stats.norm.ppf(1 - alpha/2)\n",
    "    me_2tail = critical_value_2tail * se\n",
    "    decision_2tail = \"Reject_H0\" if p_value_2tail <= alpha else \"Fail_to_reject_H0\"\n",
    "    # report\n",
    "    print(\"\" + \"Start\".center(100, '*') + \"\")\n",
    "    print(f\"{'Pooled' if pooled else 'Unpooled'} Z-Test (difference in proportions): {scope_note} scope\")\n",
    "    # create table of descriptive statistics\n",
    "    desc_head = [\"Descriptive (group): \", \"Sample size\", \"Total value\", \"Mean\", \"Standard deviation\"]\n",
    "    desc_stat = [[\"Control (A)\", control_size, f\"{np.sum(control):.5f}\", f\"{control_mean:.5f}\", f\"{control_std:.5f}\"], \n",
    "                 [\"Treatment (B)\", treatment_size, f\"{np.sum(treatment):.5f}\", f\"{treatment_mean:.5f}\", f\"{treatment_std:.5f}\"],\n",
    "                 [\"Combined\", combined_size, f\"{combined_value:.5f}\", f\"{combined_mean:.5f}\", f\"{combined_std:.5f}\"]]\n",
    "    inf_head = [\"Inferential (test): \", \"Conclusion\", \"Significance level (α)\", \"Test statistic\", \"P-value\", \"Confidence interval\", \n",
    "                \"Cohen's d\", \"Practical significance\", \"Relative change\", \"Sample size req\",\n",
    "                \"Target MDE%\", \"Equiv. sample size\"]\n",
    "    inf_stat = [[\"1-tailed\", decision_1tail, alpha, f\"{test_stat:.15f}\", f\"{p_value_1tail:.10f}\", f\"(>{(sample_stat - me_1tail):.5f} or <{(sample_stat + me_1tail):.5f})\", \n",
    "                cohen_d, practical_significance, f\"{relative_change:.5f}\", f\"{0.5*min_combined_sample_size:.0f}\",\n",
    "                target_mde, f\"{0.5*try_combined_sample_size:.0f}\"],\n",
    "                [\"2-tailed\", decision_2tail, alpha, f\"{test_stat:.15f}\", f\"{p_value_2tail:.10f}\", f\"({(sample_stat - me_2tail):.5f},{(sample_stat + me_2tail):.5f})\",\n",
    "                cohen_d, practical_significance, f\"{relative_change:.5f}\", f\"{0.5*min_combined_sample_size:.0f}\",\n",
    "                target_mde, f\"{0.5*try_combined_sample_size:.0f}\"]]\n",
    "    if full_report:\n",
    "        print() \n",
    "        print(f\"Null hypothesis (H0): There is no significant effect size difference between Control (A) and Treatment (B)\")\n",
    "        print(f\"Alternative hypothesis (H1): There is significant effect size difference between Control (A) and Treatment (B)\\n\")\n",
    "        print(f\"Conclusion (1-tail): {decision_1tail}, since p-value ({p_value_1tail:.10f}) {'<=' if p_value_1tail <= alpha else '>'} significance level ({alpha})\")\n",
    "        print(f\"Conclusion (2-tail): {decision_2tail}, since p-value ({p_value_2tail:.10f}) {'<=' if p_value_2tail <= alpha else '>'} significance level ({alpha})\\n\")\n",
    "        print(tabulate(desc_stat, headers=desc_head))\n",
    "        print()\n",
    "        print(tabulate(inf_stat, headers=inf_head))\n",
    "        print(f\"{'Sufficient' if combined_size >=  min_combined_sample_size else 'Insufficient'} sample size for observed relative change, which requires combined sample size of {min_combined_sample_size:.0f}\")\n",
    "        print(f\"Combined sample size of {try_combined_sample_size:.0f} required to detect a relative change as small as {target_mde} (at statistical power of {power}, significance level of {alpha})\")\n",
    "    # output for visualization\n",
    "    headers = [\"Scope\",\"Test\", \"Conclusion\", \"α\", \"Z*/T*\", \"SE\", \"MOE\", \n",
    "               \"sample_stat\", \"test-stat\", \"p-value\", \n",
    "               \"CI\", \"Lower_limit\", \"Upper_limit\", \n",
    "               \"A_#\", \"B_#\", \"A_value\", \"B_value\", \n",
    "               \"A_x̄\", \"B_x̄\", \"A_σ\", \"B_σ\", \n",
    "               \"cohen_d\", \"practical_sig\", \n",
    "               \"relative_change\", \"min_req_sample_size\", \n",
    "               \"target_MDE\", \"MDE_equiv_sample_size\"]\n",
    "    data = [[scope_note, f\"1-tail_z_test_{'pooled' if pooled else 'unpooled'}\", decision_1tail, alpha, f\"{critical_value_1tail:.6f}\", f\"{se:.5f}\", f\"{me_1tail:.5f}\", \n",
    "            f\"{sample_stat:.15f}\", f\"{test_stat:.15f}\", f\"{p_value_1tail:.10f}\", \n",
    "            f\"(>{(sample_stat - me_1tail):.5f}/<{(sample_stat + me_1tail):.5f})\", f\"{(sample_stat - me_1tail):.5f}\", f\"{(sample_stat + me_1tail):.5f}\", \n",
    "            control_size, treatment_size, f\"{np.sum(control):.5f}\", f\"{np.sum(treatment):.5f}\",  \n",
    "            f\"{control_mean:.5f}\", f\"{treatment_mean:.5f}\", f\"{control_std:.5f}\", f\"{treatment_std:.5f}\", \n",
    "            cohen_d, practical_significance, \n",
    "            f\"{relative_change:.5f}\", f\"{0.5*min_combined_sample_size:.0f}\", \n",
    "            target_mde, f\"{0.5*try_combined_sample_size:.0f}\"]\n",
    "             ,\n",
    "            [scope_note, f\"2-tail_z_test_{'pooled' if pooled else 'unpooled'}\", decision_2tail, alpha, f\"{critical_value_2tail:.6f}\", f\"{se:.5f}\", f\"{me_2tail:.5f}\", \n",
    "            f\"{sample_stat:.15f}\", f\"{test_stat:.15f}\", f\"{p_value_2tail:.10f}\", \n",
    "            f\"({(sample_stat - me_2tail):.5f},{(sample_stat + me_2tail):.5f})\", f\"{(sample_stat - me_2tail):.5f}\", f\"{(sample_stat + me_2tail):.5f}\", \n",
    "            control_size, treatment_size, f\"{np.sum(control):.5f}\", f\"{np.sum(treatment):.5f}\", \n",
    "            f\"{control_mean:.5f}\", f\"{treatment_mean:.5f}\", f\"{control_std:.5f}\", f\"{treatment_std:.5f}\", \n",
    "            cohen_d, practical_significance, \n",
    "            f\"{relative_change:.5f}\", f\"{0.5*min_combined_sample_size:.0f}\", \n",
    "            target_mde, f\"{0.5*try_combined_sample_size:.0f}\"]]\n",
    "    print(\"\\n\"\"EXPORT FOR VISUALIZATION:\")\n",
    "    print(tabulate(data, headers=headers))\n",
    "    print(\"\" + \"End\".center(100, '*') + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test(control, treatment, alpha, pooled, full_report, scope_note, target_mde, power):\n",
    " # convert series objects to NumPy arrays\n",
    "    control = np.asarray(control)\n",
    "    treatment = np.asarray(treatment)\n",
    "    # summary stats\n",
    "    control_mean = np.mean(control)\n",
    "    control_std = np.std(control)\n",
    "    control_size = len(control)\n",
    "    treatment_mean = np.mean(treatment)\n",
    "    treatment_std = np.std(treatment)\n",
    "    treatment_size = len(treatment)\n",
    "    combined_size = control_size + treatment_size\n",
    "    combined_value = control_size * control_mean + treatment_size * treatment_mean\n",
    "    combined_mean = combined_value / combined_size\n",
    "    pooled_var = ((control_size - 1) * np.var(control) + (treatment_size - 1) * np.var(treatment)) / (combined_size - 2)\n",
    "    combined_std = np.sqrt(pooled_var)\n",
    "    # sample_stat and proforma theoretical np Array m2 based on relative MDE \n",
    "    sample_stat = (treatment_mean - control_mean)\n",
    "    relative_change = sample_stat / control_mean\n",
    "    m2 = control * (1 + relative_change)\n",
    "    mb = control * (1 + target_mde)\n",
    "    # calculate se, cohen_d, relative MDE-based combined sample size, practical significance of cohen's d and test_stat\n",
    "    test_stat, p_value_2tail = ttest_ind(control, treatment, equal_var=pooled) \n",
    "    if pooled:\n",
    "        se = np.sqrt(pooled_var * (1 / control_size + 1 / treatment_size))\n",
    "        df = control_size + treatment_size - 2\n",
    "        cohen_d = sample_stat / np.sqrt(pooled_var)\n",
    "        effect_size = target_mde / np.sqrt((np.var(control) + np.var(m2)) / 2)\n",
    "        min_combined_sample_size = TTestIndPower().solve_power(effect_size=effect_size, alpha=alpha, power=power, ratio=1)\n",
    "        theoretical_effect_size = target_mde / np.sqrt((np.var(control) + np.var(mb)) / 2)\n",
    "        try_combined_sample_size = TTestIndPower().solve_power(effect_size=theoretical_effect_size, alpha=alpha, power=power, ratio=1)\n",
    "    else:\n",
    "        se = np.sqrt(control_std**2/control_size + treatment_std**2/treatment_size)\n",
    "        df = (control_std**2/control_size + treatment_std**2/treatment_size)**2 / ((control_std**2/control_size)**2/(control_size-1) + (treatment_std**2/treatment_size)**2/(treatment_size-1))\n",
    "        cohen_d = sample_stat / np.sqrt((control_std**2 + treatment_std**2) / 2)\n",
    "        effect_size = relative_change / np.sqrt((np.var(control) / control_size) + (np.var(m2) / control_size))\n",
    "        n = TTestIndPower().solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
    "        min_combined_sample_size = 2 * n\n",
    "        theoretical_effect_size = target_mde / np.sqrt((np.var(control) / control_size) + (np.var(mb) / control_size))\n",
    "        k = TTestIndPower().solve_power(effect_size=theoretical_effect_size, alpha=alpha, power=power)\n",
    "        try_combined_sample_size = k * 2\n",
    "    practical_significance = \"large\" if cohen_d >= 0.8 else 'medium'if cohen_d >= 0.5 else 'small' if cohen_d >= 0.2 else \"little_effect\"\n",
    "    # perform one-tailed test\n",
    "    p_value_1tail = stats.t.sf(abs(test_stat), df)\n",
    "    critical_value_1tail = stats.t.ppf(1 - alpha, df)\n",
    "    me_1tail = critical_value_1tail * se\n",
    "    decision_1tail = \"Reject_H0\" if p_value_1tail < alpha else \"Fail_to_reject_H0\"\n",
    "    # perform two-tailed test\n",
    "    critical_value_2tail = stats.t.ppf(1 - alpha/2, df)\n",
    "    me_2tail = critical_value_2tail * se\n",
    "    decision_2tail = \"Reject_H0\" if p_value_2tail < alpha else \"Fail_to_reject_H0\"\n",
    "    # report \n",
    "    print(\"\" + \"Start\".center(100, '*') + \"\")\n",
    "    print(f\"{'Pooled' if pooled else 'Unpooled'} T-Test (differences in means): {scope_note} scope\")\n",
    "    # create table of descriptive statistics\n",
    "    desc_head = [\"Descriptive (group): \", \"Sample size\", \"Total value\", \"Mean\", \"Standard deviation\"]\n",
    "    desc_stat = [[\"Control (A)\", control_size, f\"{np.sum(control):.5f}\", f\"{control_mean:.5f}\", f\"{control_std:.5f}\"], \n",
    "                 [\"Treatment (B)\", treatment_size, f\"{np.sum(treatment):.5f}\", f\"{treatment_mean:.5f}\", f\"{treatment_std:.5f}\"],\n",
    "                 [\"Combined\", combined_size, f\"{combined_value:.5f}\", f\"{combined_mean:.5f}\", f\"{combined_std:.5f}\"]]\n",
    "    inf_head = [\"Inferential (test): \", \"Conclusion\", \"Significance level (α)\", \"Test statistic\", \"P-value\", \"Confidence interval\", \n",
    "                \"Cohen's d\", \"Practical significance\", \"Relative change\", \"Sample size req\",\n",
    "                \"Target MDE%\", \"Equiv. sample size\"]\n",
    "    inf_stat = [[\"1-tailed\", decision_1tail, alpha, f\"{test_stat:.15f}\", f\"{p_value_1tail:.10f}\", f\"(>{(sample_stat - me_1tail):.5f} or <{(sample_stat + me_1tail):.5f})\", \n",
    "                cohen_d, practical_significance, f\"{relative_change:.5f}\", f\"{0.5*min_combined_sample_size:.0f}\",\n",
    "                target_mde, f\"{0.5*try_combined_sample_size:.0f}\"],\n",
    "                [\"2-tailed\", decision_2tail, alpha, f\"{test_stat:.15f}\", f\"{p_value_2tail:.10f}\", f\"({(sample_stat - me_2tail):.5f},{(sample_stat + me_2tail):.5f})\", \n",
    "                cohen_d, practical_significance, f\"{relative_change:.5f}\", f\"{0.5*min_combined_sample_size:.0f}\",\n",
    "                target_mde, f\"{0.5*try_combined_sample_size:.0f}\"]]\n",
    "    if full_report:\n",
    "        print() \n",
    "        print(f\"Null hypothesis (H0): There is no significant effect size difference between Control (A) and Treatment (B)\")\n",
    "        print(f\"Alternative hypothesis (H1): There is significant effect size difference between Control (A) and Treatment (B)\\n\")\n",
    "        print(f\"Conclusion (1-tail): {decision_1tail}, since p-value ({p_value_1tail:.10f}) {'<=' if p_value_1tail <= alpha else '>'} significance level ({alpha})\")\n",
    "        print(f\"Conclusion (2-tail): {decision_2tail}, since p-value ({p_value_2tail:.10f}) {'<=' if p_value_2tail <= alpha else '>'} significance level ({alpha})\\n\")\n",
    "        print(tabulate(desc_stat, headers=desc_head))\n",
    "        print()\n",
    "        print(tabulate(inf_stat, headers=inf_head))\n",
    "        print(f\"{'Sufficient' if combined_size >=  min_combined_sample_size else 'Insufficient'} sample size for observed relative change, which requires combined sample size of {min_combined_sample_size:.0f}\")\n",
    "        print(f\"Combined sample size of {try_combined_sample_size:.0f} required to detect a relative change as small as {target_mde} (at statistical power of {power}, significance level of {alpha})\")\n",
    "    # output for visualization\n",
    "    headers = [\"Scope\",\"Test\", \"Conclusion\", \"α\", \"Z*/T*\", \"SE\", \"MOE\", \n",
    "               \"sample_stat\", \"test-stat\", \"p-value\", \n",
    "               \"CI\", \"Lower_limit\", \"Upper_limit\", \n",
    "               \"A_#\", \"B_#\", \"A_value\", \"B_value\", \n",
    "               \"A_x̄\", \"B_x̄\", \"A_σ\", \"B_σ\", \n",
    "               \"cohen_d\", \"practical_sig\",\n",
    "               \"relative_change\", \"min_req_sample_size\",  \n",
    "                \"target_MDE\", \"MDE_equiv_sample_size\"]\n",
    "    data = [[scope_note, f\"1-tail_t_test_{'pooled' if pooled else 'unpooled'}\", decision_1tail, alpha, f\"{critical_value_1tail:.6f}\", f\"{se:.5f}\", f\"{me_1tail:.5f}\", \n",
    "            f\"{sample_stat:.15f}\", f\"{test_stat:.15f}\", f\"{p_value_1tail:.10f}\", \n",
    "            f\"(>{(sample_stat - me_1tail):.5f}/<{(sample_stat + me_1tail):.5f})\", f\"{(sample_stat - me_1tail):.5f}\", f\"{(sample_stat + me_1tail):.5f}\", \n",
    "            control_size, treatment_size, f\"{np.sum(control):.5f}\", f\"{np.sum(treatment):.5f}\",  \n",
    "            f\"{control_mean:.5f}\", f\"{treatment_mean:.5f}\", f\"{control_std:.5f}\", f\"{treatment_std:.5f}\", \n",
    "            cohen_d, practical_significance, \n",
    "            f\"{relative_change:.5f}\", f\"{0.5*min_combined_sample_size:.0f}\", \n",
    "            target_mde, f\"{0.5*try_combined_sample_size:.0f}\"]\n",
    "             ,\n",
    "            [scope_note, f\"2-tail_t_test_{'pooled' if pooled else 'unpooled'}\", decision_2tail, alpha, f\"{critical_value_2tail:.6f}\", f\"{se:.5f}\", f\"{me_2tail:.5f}\", \n",
    "            f\"{sample_stat:.15f}\", f\"{test_stat:.15f}\", f\"{p_value_2tail:.10f}\", \n",
    "            f\"({(sample_stat - me_2tail):.5f},{(sample_stat + me_2tail):.5f})\", f\"{(sample_stat - me_2tail):.5f}\", f\"{(sample_stat + me_2tail):.5f}\", \n",
    "            control_size, treatment_size, f\"{np.sum(control):.5f}\", f\"{np.sum(treatment):.5f}\", \n",
    "            f\"{control_mean:.5f}\", f\"{treatment_mean:.5f}\", f\"{control_std:.5f}\", f\"{treatment_std:.5f}\", \n",
    "            cohen_d, practical_significance, \n",
    "            f\"{relative_change:.5f}\", f\"{0.5*min_combined_sample_size:.0f}\", \n",
    "            target_mde, f\"{0.5*try_combined_sample_size:.0f}\"]]\n",
    "    print(\"\\n\"\"EXPORT FOR VISUALIZATION:\")\n",
    "    print(tabulate(data, headers=headers))\n",
    "    print(\"\" + \"End\".center(100, '*') + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power analysis (resources)\n",
    "* [Estimate sample size at given power, or power at given sample size](https://www.stat.ubc.ca/~rollin/stats/ssize/b2.html)\n",
    "* [Estimate sample size for independent proportions effect size z-test at required MDE](https://www.statsig.com/calculator) \n",
    "* [Estimate sample size for independent means  effect size t-test at required MDE](https://statulator.com/SampleSize/ss2M.html#)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data packing & results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion rate between the two groups\n",
    "conv_a = df_ab[df_ab['test_group'] == \"A: control\"].pivot_table(values='conversion', index='user_id', aggfunc='mean', fill_value=0)['conversion']\n",
    "conv_b = df_ab[df_ab['test_group'] == \"B: treatment\"].pivot_table(values='conversion', index='user_id', aggfunc='mean', fill_value=0)['conversion']\n",
    "# amount spent per user between the two groups\n",
    "spend_a = df_ab[df_ab['test_group'] == \"A: control\"].pivot_table(values='spend_USD', index='user_id', aggfunc='mean', fill_value=0)['spend_USD']\n",
    "spend_b = df_ab[df_ab['test_group'] == \"B: treatment\"].pivot_table(values='spend_USD', index='user_id', aggfunc='mean', fill_value=0)['spend_USD']\n",
    "z_test(conv_a, conv_b, 0.05, False, True, 'overall', 0.129, 0.80)\n",
    "t_test(spend_a, spend_b, 0.05, False, True, 'overall', 0.129, 0.80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
